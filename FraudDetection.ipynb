{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DQidViss_io-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the data with a specified encoding\n",
        "try:\n",
        "    data = pd.read_csv('/content/Complaint_Dataset.csv', encoding='utf-8')\n",
        "except UnicodeDecodeError:\n",
        "    data = pd.read_csv('/content/Complaint_Dataset.csv', encoding='latin1')  # or try 'iso-8859-1'\n",
        "\n",
        "# Preprocess the data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['Description'])\n",
        "\n",
        "# Convert texts to sequences\n",
        "sequences = tokenizer.texts_to_sequences(data['Description'])\n",
        "padded_sequences = pad_sequences(sequences, padding='post')\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(data['Category'])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, LayerNormalization, Dropout, GlobalAveragePooling1D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define a custom transformer layer\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Define the model\n",
        "embed_dim = 64  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = Input(shape=(X_train.shape[1],))\n",
        "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embed_dim)(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(embedding_layer)\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "outputs = Dense(len(label_encoder.classes_), activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z_FzEY3BrpF",
        "outputId": "69247037-3948-4656-9217-94cc079835cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "14/14 [==============================] - 19s 1s/step - loss: 1.6002 - accuracy: 0.3310 - val_loss: 1.4453 - val_accuracy: 0.3761\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 10s 753ms/step - loss: 1.3734 - accuracy: 0.4699 - val_loss: 1.3160 - val_accuracy: 0.4587\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 11s 789ms/step - loss: 1.1936 - accuracy: 0.5347 - val_loss: 1.1968 - val_accuracy: 0.6789\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 10s 760ms/step - loss: 1.0345 - accuracy: 0.5949 - val_loss: 1.0316 - val_accuracy: 0.7523\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 9s 661ms/step - loss: 0.8682 - accuracy: 0.6921 - val_loss: 0.7660 - val_accuracy: 0.7798\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 11s 780ms/step - loss: 0.6388 - accuracy: 0.8032 - val_loss: 0.5977 - val_accuracy: 0.8073\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 11s 810ms/step - loss: 0.4944 - accuracy: 0.8333 - val_loss: 0.5656 - val_accuracy: 0.8440\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 10s 746ms/step - loss: 0.2546 - accuracy: 0.9259 - val_loss: 0.4419 - val_accuracy: 0.8165\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 10s 702ms/step - loss: 0.1549 - accuracy: 0.9491 - val_loss: 0.3921 - val_accuracy: 0.8440\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 11s 742ms/step - loss: 0.0495 - accuracy: 0.9861 - val_loss: 0.6301 - val_accuracy: 0.8165\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 11s 788ms/step - loss: 0.0659 - accuracy: 0.9722 - val_loss: 0.3575 - val_accuracy: 0.8624\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 11s 787ms/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.4954 - val_accuracy: 0.8624\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 9s 671ms/step - loss: 0.0109 - accuracy: 0.9954 - val_loss: 0.3971 - val_accuracy: 0.8807\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 10s 689ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.8807\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 11s 784ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.8716\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 11s 788ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.8807\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 9s 667ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.8807\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 10s 731ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.8716\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 11s 785ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.8716\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 11s 791ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.8716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict category for new descriptions\n",
        "def predict_category(description):\n",
        "    sequence = tokenizer.texts_to_sequences([description])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=padded_sequences.shape[1], padding='post')\n",
        "    prediction = model.predict(padded_sequence)\n",
        "    return label_encoder.inverse_transform([prediction.argmax()])[0]\n",
        "\n",
        "# Test the model\n",
        "test_description = '''I am writing to formally bring to your attention the disturbing issue of defamatory content being posted against our esteemed institution, Maharana Pratap Group of Institutions (mpgi_official), on the social media platform Instagram. The Instagram handle in question, @mpgi_kingdom, has been consistently posting derogatory and distasteful jokes targeting our faculty and students.\n",
        "\n",
        "MPGI takes great pride in upholding a respectful and inclusive environment for all members of our community, and it is deeply concerning to see such harmful content circulating online. The defamatory nature of these posts not only tarnishes the reputation of our institution but also has the potential to harm the well-being and morale of our faculty, staff, and students.\n",
        "\n",
        "We have attempted to address this issue directly with the owner of the Instagram handle, but our attempts have been unsuccessful in halting the dissemination of offensive content. Therefore, we are seeking your assistance in taking appropriate action to address this matter and ensure that such defamatory posts are promptly removed from the platform.\n",
        "\n",
        "Enclosed with this letter are examples of the defamatory posts for your review and investigation. We kindly request that the cyber cell investigate this matter thoroughly and take necessary actions in accordance with the relevant laws and regulations governing cyber defamation.\n",
        "\n",
        "We understand the gravity of this situation and trust that you will handle this matter.'''\n",
        "predicted_category = predict_category(test_description)\n",
        "print(f'Predicted Category: {predicted_category}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtayV5kvAhoy",
        "outputId": "a7afa664-55e0-43ea-9ed5-18bc97c34c5d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicted Category: Defamation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('loan_fraud_model.h5', save_format='h5', include_optimizer=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5epJg6sM0fe",
        "outputId": "2a3a6dfb-d833-41f8-bd36-5abde7960364"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "# Register the custom object\n",
        "get_custom_objects().update({'TransformerBlock': TransformerBlock})\n",
        "\n",
        "# Load the model with custom objects\n",
        "loaded_model = load_model('loan_fraud_model.h5')\n"
      ],
      "metadata": {
        "id": "vvkwPArLNGgh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict category for new descriptions\n",
        "def predict_category(description):\n",
        "    sequence = tokenizer.texts_to_sequences([description])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=padded_sequences.shape[1], padding='post')\n",
        "    prediction = loaded_model.predict(padded_sequence)\n",
        "    return label_encoder.inverse_transform([prediction.argmax()])[0]\n",
        "\n",
        "# Test the model\n",
        "test_description = \"Victim received a call from an unknown number claiming to be a loan officer.\"\n",
        "predicted_category = predict_category(test_description)\n",
        "print(f'Predicted Category: {predicted_category}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKwENM6VNxkp",
        "outputId": "6b2ec7e5-8561-4b92-a603-d29f109de42d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 206ms/step\n",
            "Predicted Category: Online Loan Fraud\n"
          ]
        }
      ]
    }
  ]
}